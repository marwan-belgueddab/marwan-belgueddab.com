[{"content":"I didn\u0026rsquo;t think agentic workflows would ever apply to me. In fact, I actively refused to jump into the AI hype of 2024 and 2025. I disliked the sensationalist headlines and the \u0026ldquo;dream selling\u0026rdquo; that dominated the industry. Today, I\u0026rsquo;m playing catch-up, but looking back, I still believe my initial hesitation was the right decision.\nI initially stuck to what felt useful: simple text-to-text interactions. I used ChatGPT when it launched, experimented with Bing Chat and Bard, and dabbled with open-source tools via Ollama. However, the results often felt lackluster, so I let them be. My exposure through work was sufficient to keep me in the loop without diving in headfirst.\nAs the landscape shifted with new tools and approaches, I continued to watch from afar, testing Gemini CLI rapidly or building simple custom Gems, but nothing substantial. I lacked a compelling use case, specifically one that didn\u0026rsquo;t involve sharing personal data with an LLM. Furthermore, I hadn\u0026rsquo;t touched raw code in a decade; my work focused on Infrastructure as Code (IaC) and configuration management, areas where early LLMs struggled and posed significant security risks.\nHowever, late in 2024, I used AI to document my homelab, and for the first time, it was \u0026ldquo;good enough.\u0026rdquo; Since then, products have evolved to cover more complex use cases. I have changed how I work, both professionally and in my spare time, adapting agents and AI tools into a seamless workflow.\nHow I Work: The \u0026ldquo;Project\u0026rdquo; Approach My core work hasn\u0026rsquo;t changed much over the last two years; I still focus on IaC and non-coding technical topics. However, I now utilize the same toolset a software developer would.\nI treat every task as a distinct \u0026ldquo;Project.\u0026rdquo; Whether I am researching winter tires or architecting a cloud solution, I create a new directory in my personal drive. It starts with a raw_notes.md file containing my brain dump: what I want, what I think I want, known information, and known unknowns.\n1. Research \u0026amp; Ideation: Gemini Web For initial research, I use Gemini directly alongside standard search engines. It acts as a sounding board, helping me compare options and decide on parameters for unfamiliar topics.\nI often ask it to explain concepts using analogies that resonate with my background. Much like the \u0026ldquo;explain in football terms\u0026rdquo; memes, I ask for explanations that map to my existing knowledge. While I initially created a custom Gem for this, I now simply prompt it ad-hoc when clarification is needed.\n2. The Powerhouse: Gemini CLI The second, and perhaps most transformative, tool that really convinced me to use an agentic workflow is the Gemini CLI. It has been a life-changing addition to my use of AI and productivity.\nIf I were researching car tires, I would open the CLI in my project directory and instruct it to find information specific to my vehicle. Unlike a standard chat, I can provide a GEMINI.md file in the directory. This file acts as a persistent custom prompt, instructing the agent on how to behave globally or per project.\nKey Capabilities:\nSystem Interaction: It can run terminal commands, allowing for quick prototyping and script creation.\nSelf-Correction: If a command fails, it analyzes the error output and attempts to fix it automatically.\nExtensions \u0026amp; Skills: Using Gemini CLI Extensions, it can interact with external tools.\nConductor: I use the Conductor extension to transform rough ideas into proper implementation plans (e.g., conductor:plan), ensuring a structured approach before execution.\nUnlike Claude, which summons multiple sub-agents, Gemini CLI typically feels like interacting with a single agent. When I need research output, I ask it to generate a Markdown report. I wait for it to finish writing the file, then read it directly, eliminating the tedious copy-paste loop from a web browser. (Although now you can find reports in your Google Drive too, found via Gemini Web). Another way I really like using gemini-cli is for quick scripting and/or working on a single document, maybe two. I don’t need a full IDE, and I need a more capable tool than the web to directly interact with my code and system.\n3. The Agent-First IDE: Google Antigravity The third tool I\u0026rsquo;ve adopted is Google Antigravity.\nPreviously, I used VS Code with Copilot, refusing to pay for Cursor as I didn\u0026rsquo;t see the value add, and like I said, I refused to jump into that weird AI trend of tools for agents. Mostly because I felt they were just hype and nothing my current tools could do with an update (and I was right). But I still jumped from VS Code because Antigravity changed that. It allows me to leverage my Gemini subscription while also accessing Claude and GPT-OSS 120B models within a unified interface. Yes I could use VS Code with GitHub Copilot, but I already have a subscription to Gemini, and I like the Agent-First approach for Antigravity.\nI use Antigravity for larger projects requiring multi-file context. My approach here is deliberate; I don\u0026rsquo;t just say \u0026ldquo;do this\u0026rdquo; and burn through tokens. I arrive prepared with a complete design document, often refined by the previous two steps (Gemini Web and Gemini CLI).\nThe Workflow:\nOpen the project directory and add the design document.\nAsk Gemini to review the document and it will prepare an implementation plan that is formatted in a way the agents will understand. This completes the design_document.md file.\nReview the automated plan, adding comments if key points are missing. And it’s a feature I really like because I can instruct the agent to rework the plan on a specific part if it doesn’t suit me. Much like when you work with colleagues on Google Docs and leave a comment because they didn’t complete their part.\nInstruct the agent to create the necessary artifacts, and validate every command line in the terminal. You could go yolo, but I rather supervise what is happening and stop it if it deviates.\nThis method allows me to modify documents and code with autocomplete support, significantly speeding up development.\nThe Risks: Vibe-Coding vs. Reality I\u0026rsquo;ve decided I won\u0026rsquo;t go back to working without LLMs for tasks taking more than a few hours. I offload repetitive, annoying work to agents, focusing my energy on problem-solving and the \u0026ldquo;fun parts\u0026rdquo; of engineering for me: finding problems and then finding solutions for 3 hours while learning about something new. All while getting frustrated because some documentation was poorly written and I didn’t understand it on the first read.\nHowever, this \u0026ldquo;vibe-coding\u0026rdquo; approach comes with risks.\nThe \u0026ldquo;Touch Grass\u0026rdquo; Factor Using these tools provides a genuine dopamine hit. Watching an agent magically generate code and watching it use the terminal while generating an output that would take you days in minutes is satisfying and addictive. It’s easy to get lost in the flow, so I have to remind myself to take a step back and not rely on them for everything.\nTrust, but Verify The biggest risk is delegating too much cognitive load without reflection. Machines, no matter how advanced, need critical thinking oversight. They are facilitators, not replacements.\nIf anyone tells you \u0026ldquo;you just don\u0026rsquo;t know how to prompt\u0026rdquo; or that \u0026ldquo;prompt engineering is the only skill you need,\u0026rdquo; run. If you don\u0026rsquo;t understand the underlying technology, you won\u0026rsquo;t understand what the tool is doing.\nA Real-World Example: Security Failures\nI recently used these tools to write Ansible and Terraform code for deploying resources on Google Cloud Platform (GCP). My organization has strict policies: no external IPs for compute resources and mandatory Identity-Aware Proxy (IAP) usage.\nI ran three different prompts:\nDeploy containers on GKE I reach via an IP address or a fqdn.\nSecurely deploy this container using a hub-and-spoke architecture.\nDeploy resources with explicit security constraints (No external IP, follow org policies), including a reference to the Google Cloud FAST fabric documentation.\nIn all three cases, the agents created modules that tried to deploy resources with direct internet access, violating organization policies. Even when I explicitly described the constraints, the agents occasionally used manual gcloud commands or ignored the policy checks.\nI had to intervene, explicitly forcing the agent to \u0026ldquo;pull the policies to confirm constraints\u0026rdquo; before acting. A user without foundational knowledge would have been happy with the result, unknowingly deploying an insecure infrastructure. That is why I still think it is important to have a solid foundation in the underlying technology. And I don\u0026rsquo;t plan on skipping that, I spend a lot of time reading on the subjects, doing research and testing, a lot. Sometimes I barely trust my own knowledge, there\u0026rsquo;s no reason to trust AI more.\nConclusion These tools have exposed some of my weak points and forced me to improve. I now spend more time researching and planning than before, and more importantly, I write more complete and clearer requirements for my \u0026ldquo;projects,\u0026rdquo; whether I will use AI or not.\nI remain mindful of how I use AI. I\u0026rsquo;m not trying to stay on the bleeding edge of every new release. Instead, I\u0026rsquo;ve found a pragmatic stack that works for me. It helps me spend less time on boilerplate and more time with my family and hobbies, while still allowing me to reach technical heights I couldn\u0026rsquo;t achieve before.\nAnd I will make sure to use AI to raise the floor: of my knowledge and my quality of life, while still being mindful of its risks and implications on society.\nResources Gemini CLI: GitHub Repository Google Antigravity: Official Documentation Extensions: Gemini CLI Extensions Gallery Skills: Anthropic Skills ","date":"2026-01-21T00:00:00Z","permalink":"https://marwan-belgueddab.com/p/skeptic-to-agentic-workflow/","title":"From skeptic to agentic: Playing catch-up with AI on my terms"},{"content":"Introduction How many of us start a hobby intending to build a sprawling network infrastructure? I certainly didn’t. I started building a homelab simply to learn new technologies and keep my data close. What began with an old desktop, followed by a small NAS and a Raspberry Pi, has grown into a multi-node cluster housed in a 15U rack. It is something that honestly still surprises me! It wasn\u0026rsquo;t the initial goal, but rather a natural consequence of exploring and learning.\nOver the past few years, I’ve rebuilt my homelab almost annually, starting from scratch each time because I wanted to implement the new things I had learned. This process revealed how much my approach has evolved since I began. Initially, it was all about mastering the technical aspects, such as understanding hypervisors, Kubernetes, and VLANs, but now I realize there is so much more to it than just the technical challenges.\nShifting From Chaos to Strategy: A Business-Inspired Approach Each year, my decision-making process for implementing changes in the lab shifted. It was often driven by budget constraints or current hardware limitations. This year, I decided to be more deliberate and create a structured plan, moving beyond simply choosing technologies based on specs or available gear.\nI started applying principles I’ve seen used in businesses. First, I define a business goal: a concise sentence that guides the entire plan and sets the direction for more detailed objectives. This prevents me from getting lost in endless possibilities. Following this, I create an executive summary, expanding on the initial goal with more technical details. For example, my goal this year was to Reduce manual intervention and improve network performance and hardware efficiency. This translated into building a more secure, fault-tolerant, and automated lab using all available hardware while improving connection speed and reducing bottlenecks.\nThis helped me define key terms to guide my technical decisions and, crucially, establish clear criteria for success. Simply stating a goal isn’t enough; you need to know how to measure whether you’ve achieved it, how do you know when the project is complete?\nSince the primary beneficiary was myself, measuring success required a different perspective and it was a valuable exercise. Naturally, I established constraints (like avoiding unwelcome calls from my bank!) and documented what I knew and what remained uncertain.\nMore Than Just Tech: The Unexpected Benefits \u0026amp; Impact This process gave me much greater clarity about my direction. It even required me to re-evaluate some initial decisions, thankfully, nothing drastic! The journey involved research, note-taking, and iterative refinement until a clear path emerged. Once the plan was solid, implementation became significantly smoother.\nI’m accustomed to creating technical plans from business requirements in a professional setting and it\u0026rsquo;s standard practice for many people. Initially, I viewed this as a purely work-related methodology. However, integrating elements of that framework with my own more spontaneous approach proved surprisingly powerful. It helped me focus and avoid the trap of endless searching for ‘the perfect’ solution.\nHaving a homelab is incredibly rewarding as I enjoy computers, tinkering, and especially troubleshooting problems (often ones I create myself). It\u0026rsquo;s become my favorite hobby. The ability to solve these challenges has brought me to where I am today, though I’m acutely aware of the role luck plays in my journey. I often wonder if my enjoyment stemmed from a love of fixing things or if it was simply that constantly troubleshooting computers honed my problem-solving skills.\nDespite the time, occasional frustrations, and financial investment, I’m immensely satisfied with my homelab journey. Beyond the technical aspects, it has had a mostly positive impact on those around me.\nTo be frank, for a long time, I didn\u0026rsquo;t understand why people didn\u0026rsquo;t get into IT the way I did. I would try to impose my complicated setups on them. But then I realized something important: I don\u0026rsquo;t know how to sew properly, fix every issue with my car, or plumbing. Those are critical skills for everyday life, but they aren\u0026rsquo;t my strong suits. Others are better at those things than I am. So, my role should be to use my specific skills to make technology easier for them, not more complicated.\nMy knowledge allows me to maximize our resources and improve our quality of life, even in small ways. That is why I reworked my lab this year around fault tolerance. If the DNS at home fails, the internet stops working, and that impacts everyone\u0026rsquo;s work at home.\nConclusion: More than a hobby, a path to growth Ultimately, my homelab has been a vehicle for exploring my passion for technology. While it’s satisfying to demonstrate what I can build, it\u0026rsquo;s important to also value self reflection: understanding what I’ve accomplished, how I learned, and where I can improve. This approach has shown me new avenues for growth and self-discovery, proving that even a personal hobby can help me grow and humble me. From thinking that my solution is the best to actually creating a solution that has a positive impact for all.\nI have moved from thinking that my solution is the best, to actually creating a solution that has a positive impact on everyone involved. Don\u0026rsquo;t get me wrong, I don\u0026rsquo;t view my lab differently than before, a nice and very fulfilling hobby. However, now I take a step back to reflect on what I\u0026rsquo;m building, using my skills to serve and be useful to those around me and beyond.\n","date":"2025-11-24T00:00:00Z","permalink":"https://marwan-belgueddab.com/p/homelab-beyond-tech-lessons/","title":"Beyond Tech - What a Homelab Taught Me"}]